{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c642f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a0ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt #data visualization\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split # Split data to train and test data(after merging in this case)\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# import libraries from tensorflow\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout,Input, BatchNormalization, LeakyReLU, ReLU\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import plot_model\n",
    "#from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.initializers import HeUniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12424866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the loaded model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the entire model\n",
    "loaded_model = load_model(\"IL_trained_model_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d67ef7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orientation Loss</th>\n",
       "      <th>Edge Coverage</th>\n",
       "      <th>Average Thickness</th>\n",
       "      <th>Average Separation</th>\n",
       "      <th>Distance Entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037.830566</td>\n",
       "      <td>16.6758</td>\n",
       "      <td>1.8025</td>\n",
       "      <td>2.6209</td>\n",
       "      <td>0.9644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>342.689941</td>\n",
       "      <td>13.3282</td>\n",
       "      <td>2.1457</td>\n",
       "      <td>3.1926</td>\n",
       "      <td>0.9648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>762.545898</td>\n",
       "      <td>17.9451</td>\n",
       "      <td>1.6979</td>\n",
       "      <td>2.3449</td>\n",
       "      <td>0.9704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>465.277466</td>\n",
       "      <td>12.7644</td>\n",
       "      <td>2.3037</td>\n",
       "      <td>3.4747</td>\n",
       "      <td>0.9607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>984.840271</td>\n",
       "      <td>16.6378</td>\n",
       "      <td>1.8696</td>\n",
       "      <td>2.5217</td>\n",
       "      <td>0.9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>125.517296</td>\n",
       "      <td>13.5489</td>\n",
       "      <td>2.4059</td>\n",
       "      <td>2.7382</td>\n",
       "      <td>0.9982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1504.066284</td>\n",
       "      <td>19.8257</td>\n",
       "      <td>1.5317</td>\n",
       "      <td>2.2086</td>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1367.129272</td>\n",
       "      <td>20.7555</td>\n",
       "      <td>1.5467</td>\n",
       "      <td>2.0168</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>855.029663</td>\n",
       "      <td>21.8735</td>\n",
       "      <td>1.5065</td>\n",
       "      <td>1.9006</td>\n",
       "      <td>0.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>439.846100</td>\n",
       "      <td>16.5547</td>\n",
       "      <td>1.9643</td>\n",
       "      <td>2.4226</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Orientation Loss  Edge Coverage  Average Thickness  Average Separation  \\\n",
       "0       1037.830566        16.6758             1.8025              2.6209   \n",
       "1        342.689941        13.3282             2.1457              3.1926   \n",
       "2        762.545898        17.9451             1.6979              2.3449   \n",
       "3        465.277466        12.7644             2.3037              3.4747   \n",
       "4        984.840271        16.6378             1.8696              2.5217   \n",
       "5        125.517296        13.5489             2.4059              2.7382   \n",
       "6       1504.066284        19.8257             1.5317              2.2086   \n",
       "7       1367.129272        20.7555             1.5467              2.0168   \n",
       "8        855.029663        21.8735             1.5065              1.9006   \n",
       "9        439.846100        16.5547             1.9643              2.4226   \n",
       "\n",
       "   Distance Entropy  \n",
       "0            0.9644  \n",
       "1            0.9648  \n",
       "2            0.9704  \n",
       "3            0.9607  \n",
       "4            0.9765  \n",
       "5            0.9982  \n",
       "6            0.9603  \n",
       "7            0.9778  \n",
       "8            0.9804  \n",
       "9            0.9892  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load custom input data\n",
    "# Import dataset\n",
    "\n",
    "df_test = pd.read_csv(\"TestData.csv\") #reading the provided dataset\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c73f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data scaler from the saved file\n",
    "loaded_scaler_testdata = joblib.load('scale_testdata.pkl')\n",
    "# Load the scaler from the saved file ( to get original scale to convert to actual values )\n",
    "loaded_scaler_originalval = joblib.load('scaler_originalval.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723f7029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3996857 , -0.37723648, -0.2013607 ,  0.39453831, -1.16207511],\n",
       "       [-0.96035944, -1.25657267,  0.72307299,  1.35493974, -1.13659549],\n",
       "       [-0.13890975, -0.04382108, -0.48310826, -0.06911534, -0.7798808 ],\n",
       "       [-0.72051651, -1.40466973,  1.14865727,  1.82884081, -1.3977616 ],\n",
       "       [ 0.29601   , -0.38721819, -0.02062206,  0.22789178, -0.39131658],\n",
       "       [-1.38525851, -1.19859994,  1.42394026,  0.59159111,  0.99095285],\n",
       "       [ 1.31187757,  0.45016854, -0.93077982, -0.29808633, -1.42324122],\n",
       "       [ 1.04395981,  0.69440524, -0.89037625, -0.62029203, -0.30850781],\n",
       "       [ 0.04203508,  0.98807768, -0.99865782, -0.81549693, -0.14289028],\n",
       "       [-0.77027307, -0.40904662,  0.23445915,  0.06141324,  0.41766138]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit: calculates the statistics (like mean and standard deviation for StandardScaler)\n",
    "# from the data that the scaler needs to perform the transformation.\n",
    "# transform: This step applies the calculated scaling/transformations to the data.\n",
    "TestData = loaded_scaler_testdata.transform(df_test)\n",
    "TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56beb134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the loaded_model to make predictions on your test data\n",
    "predictions = loaded_model.predict(TestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f046b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Zoom, Predicted Focus, Predicted Contrast \n",
      "[[2.1710621e+04 6.1790309e+00 6.8929832e+01]\n",
      " [4.3699918e+04 7.2661109e+00 6.8523415e+01]\n",
      " [2.1759262e+04 6.8399158e+00 6.7856842e+01]\n",
      " [4.9319180e+04 6.4465256e+00 6.9392853e+01]\n",
      " [2.2122727e+04 6.1949096e+00 6.8843987e+01]\n",
      " [4.5934176e+04 6.9459634e+00 6.7028366e+01]\n",
      " [8.1072568e+03 6.2194281e+00 6.8701950e+01]\n",
      " [1.0372207e+04 7.4517455e+00 6.8737587e+01]\n",
      " [8.2946680e+03 7.7040062e+00 6.7057861e+01]\n",
      " [2.7338906e+04 7.2092552e+00 6.7588333e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Use the scaler to transform the predicted values back to their original scale\n",
    "predictions_testdata = loaded_scaler_originalval.inverse_transform(predictions)\n",
    "\n",
    "print(\"Predicted Zoom, Predicted Focus, Predicted Contrast \")\n",
    "print(predictions_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374bc4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the relevant columns in the DataFrame with the predicted values\n",
    "df_test[['Predicted Zoom', 'Predicted Focus', 'Predicted Contrast']] = predictions_testdata\n",
    "\n",
    "# Save the DataFrame back to the same CSV file\n",
    "df_test.to_csv(\"TestData.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a9dcba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
